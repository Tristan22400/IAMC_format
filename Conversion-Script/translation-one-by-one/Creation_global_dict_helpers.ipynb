{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read normal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()\n",
    "\n",
    "\n",
    "def get_last_added_file(folder_path):\n",
    "    # Get a list of all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Filter Excel files\n",
    "    excel_files = [\n",
    "        file\n",
    "        for file in files\n",
    "        if file.endswith(\".xlsx\") or file.endswith(\".xls\") or file.endswith(\".csv\")\n",
    "    ]\n",
    "\n",
    "    if not excel_files:\n",
    "        return None  # No Excel files found\n",
    "    print()\n",
    "    # Sort files by modification time (newest first)\n",
    "    excel_files.sort(\n",
    "        key=lambda x: os.path.getctime(os.path.join(folder_path, x)), reverse=True\n",
    "    )\n",
    "\n",
    "    # Return the path to the last added Excel file\n",
    "    return os.path.join(folder_path, excel_files[0])\n",
    "\n",
    "\n",
    "def create_folder_if_not_exists(folder_name):\n",
    "    # Get current folder\n",
    "    folder_path = os.getcwd()\n",
    "\n",
    "    try:\n",
    "        os.makedirs(\"pip\")\n",
    "        print(\"DONE\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    if not os.path.exists(os.path.join(folder_path, folder_name)):\n",
    "        os.makedirs(folder_name)\n",
    "        print(\"Folder '{}' created.\".format(folder_name))\n",
    "    else:\n",
    "        print(\"Folder '{}' already exists.\".format(folder_name))\n",
    "\n",
    "\n",
    "# Folder name to create\n",
    "folder_name_to_convert = \"File_To_Convert\"\n",
    "folder_name_converted = \"File_Converted\"\n",
    "\n",
    "# Get current folder\n",
    "folder_path = os.getcwd()\n",
    "\n",
    "\n",
    "# Create new folder\n",
    "create_folder_if_not_exists(folder_name_converted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last upload excel file\n",
    "real_folder_path = os.path.join(folder_path, folder_name_to_convert)\n",
    "\n",
    "last_file = get_last_added_file(real_folder_path)\n",
    "\n",
    "\n",
    "if last_file:\n",
    "    print(\"Last added file:\", last_file)\n",
    "else:\n",
    "    print(\"No files found in the folder.\")\n",
    "\n",
    "# Get the correct naming for the converted file\n",
    "filename_with_extension = os.path.basename(last_file)\n",
    "splited_filename_with_extension = os.path.splitext(filename_with_extension)\n",
    "print(splited_filename_with_extension)\n",
    "filename = (\n",
    "    splited_filename_with_extension[0]\n",
    "    + \"converted\"\n",
    "    + splited_filename_with_extension[1]\n",
    ")\n",
    "\n",
    "# Possibility to create a thread to run all the code during the wait for the user answer.\n",
    "# scenario = input(\"Give the name of the scenario\")\n",
    "scenario = splited_filename_with_extension[0]\n",
    "\n",
    "# Read the selected file\n",
    "if (\n",
    "    splited_filename_with_extension[1] == \".xls\"\n",
    "    or splited_filename_with_extension[1] == \".xlsx\"\n",
    "):\n",
    "    scenario_variable_df = pd.read_excel(last_file)\n",
    "elif splited_filename_with_extension[1] == \".csv\":\n",
    "    scenario_variable_df = pd.read_csv(last_file)\n",
    "\n",
    "\n",
    "scenario_variable_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_rows = scenario_variable_df[scenario_variable_df.duplicated()]\n",
    "\n",
    "# Display duplicate rows\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicate_rows)\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "num_duplicate_rows = duplicate_rows.shape[0]\n",
    "print(\"Number of Duplicate Rows:\", num_duplicate_rows)\n",
    "\n",
    "scenario_variable_df = scenario_variable_df.drop_duplicates()\n",
    "print(len(scenario_variable_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column of the file\n",
    "columns = scenario_variable_df.columns.str.replace(\"Unnamed:\", \"Subscript\")\n",
    "columns = columns.str.replace(\".\", \" \")\n",
    "\n",
    "# Define the string you want in column names\n",
    "search_string = \"Subscript\"\n",
    "counter = 0\n",
    "\n",
    "for k in range(len(columns)):\n",
    "    if search_string in columns[k]:\n",
    "        columns.values[k] = search_string + \" \" + str(counter)\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "# Create a dictionary using zip() and dictionary comprehension\n",
    "my_dict = {k: v for k, v in zip(scenario_variable_df.columns[2:6], columns[2:6])}\n",
    "scenario_variable_df.rename(columns=my_dict, inplace=True)\n",
    "scenario_variable_df.rename(\n",
    "    columns={\"Time\": \"Variable\", \"Year\": \"Unit\", \"Subscript\": \"Subscript 0\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Insert the three columns in the right place for IAMC format\n",
    "scenario_variable_df.insert(0, \"Model\", \"WILIAM\")\n",
    "scenario_variable_df.insert(1, \"Scenario\", scenario)\n",
    "scenario_variable_df.insert(2, \"Region\", \"World\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict used to check if the subscripts are a country\n",
    "country_dict = {\n",
    "    \"EU27\": 1,\n",
    "    \"UK\": 1,\n",
    "    \"CHINA\": 1,\n",
    "    \"EASOC\": 1,\n",
    "    \"INDIA\": 1,\n",
    "    \"LATAM\": 1,\n",
    "    \"RUSSIA\": 1,\n",
    "    \"USMCA\": 1,\n",
    "    \"LROW\": 1,\n",
    "    \"AUSTRIA\": 1,\n",
    "    \"BELGIUM\": 1,\n",
    "    \"BULGARIA\": 1,\n",
    "    \"CROATIA\": 1,\n",
    "    \"CYPRUS\": 1,\n",
    "    \"CZECH_REPUBLIC\": 1,\n",
    "    \"DENMARK\": 1,\n",
    "    \"ESTONIA\": 1,\n",
    "    \"FINLAND\": 1,\n",
    "    \"FRANCE\": 1,\n",
    "    \"GERMANY\": 1,\n",
    "    \"GREECE\": 1,\n",
    "    \"HUNGARY\": 1,\n",
    "    \"IRELAND\": 1,\n",
    "    \"ITALY\": 1,\n",
    "    \"LATVIA\": 1,\n",
    "    \"LITHUANIA\": 1,\n",
    "    \"LUXEMBOURG\": 1,\n",
    "    \"MALTA\": 1,\n",
    "    \"NETHERLANDS\": 1,\n",
    "    \"POLAND\": 1,\n",
    "    \"PORTUGAL\": 1,\n",
    "    \"ROMANIA\": 1,\n",
    "    \"SLOVAKIA\": 1,\n",
    "    \"SLOVENIA\": 1,\n",
    "    \"SPAIN\": 1,\n",
    "    \"SWEDEN\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "# Aggregate the subscripts at the end of the variable\n",
    "def aggregate_variable_name(row, counter):\n",
    "    for k in range(counter):\n",
    "        subscript = row[\"Subscript \" + str(k)]\n",
    "\n",
    "        if k == 0:\n",
    "            if country_dict.get(subscript) == 1:\n",
    "                # Give the name of the region for that variable\n",
    "                row[\"Region\"] = subscript\n",
    "\n",
    "                row[\"Subscript 0\"] = np.nan\n",
    "                continue\n",
    "\n",
    "        if not pd.isnull(subscript):\n",
    "            row[\"Variable\"] = row[\"Variable\"] + \"|\" + subscript\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "# Apply the previous function on all the lines\n",
    "scenario_variable_df = scenario_variable_df.apply(\n",
    "    aggregate_variable_name, args=(counter,), axis=1\n",
    ")\n",
    "\n",
    "# Remove the subscript columns once they have been added at the end of the variable name\n",
    "drop_columns_list = [\"Subscript \" + str(k) for k in range(counter)]\n",
    "scenario_variable_df.drop(columns=drop_columns_list, inplace=True)\n",
    "\n",
    "scenario_variable_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Transform variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last upload excel file\n",
    "real_folder_path= os.path.join(folder_path , folder_name_to_convert)\n",
    "\n",
    "last_file = get_last_added_file(real_folder_path)\n",
    "\n",
    "\n",
    "if last_file:\n",
    "    print(\"Last added file:\", last_file)\n",
    "else:\n",
    "    print(\"No files found in the folder.\")\n",
    "\n",
    "# Get the correct naming for the converted file \n",
    "filename_with_extension = os.path.basename(last_file)\n",
    "splited_filename_with_extension = os.path.splitext(filename_with_extension)\n",
    "print(splited_filename_with_extension)\n",
    "filename = splited_filename_with_extension[0] + 'converted' + splited_filename_with_extension[1]\n",
    "\n",
    "# Possibility to create a thread to run all the code during the wait for the user answer. \n",
    "# scenario = input(\"Give the name of the scenario\")\n",
    "scenario = splited_filename_with_extension[0]\n",
    "\n",
    "# Read the selected file \n",
    "if splited_filename_with_extension[1] == '.xls' or splited_filename_with_extension[1] == '.xlsx':\n",
    "    scenario_variable_2_df = pd.read_excel(last_file)\n",
    "elif  splited_filename_with_extension[1] == '.csv': \n",
    "    scenario_variable_2_df = pd.read_csv(last_file)\n",
    "\n",
    "\n",
    "scenario_variable_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the column of the file \n",
    "columns = scenario_variable_2_df.columns.str.replace('Unnamed:', 'Subscript')\n",
    "columns = columns.str.replace('.', ' ')\n",
    "\n",
    "# Define the string you want in column names\n",
    "search_string = 'Subscript'\n",
    "counter=0 \n",
    "\n",
    "for k in range(len(columns)): \n",
    "    if search_string in columns[k]: \n",
    "        columns.values[k]= search_string + ' ' + str(counter)\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "\n",
    "# Create a dictionary using zip() and dictionary comprehension\n",
    "my_dict = {k: v for k, v in zip(scenario_variable_2_df.columns[2:6], columns[2:6])}\n",
    "scenario_variable_2_df.rename(columns=my_dict, inplace=True)\n",
    "scenario_variable_2_df.rename(columns={\"Time\": \"Variable\", \"Year\": \"Unit\", \"Subscript\":\"Subscript 0\"}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Insert the three columns in the right place for IAMC format\n",
    "scenario_variable_2_df.insert(0, 'Model', \"WILIAM\")\n",
    "scenario_variable_2_df.insert(1, 'Scenario', scenario)\n",
    "scenario_variable_2_df.insert(2,\"Region\",\"World\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_rows = scenario_variable_2_df[scenario_variable_2_df.duplicated()]\n",
    "\n",
    "# Display duplicate rows\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicate_rows)\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "num_duplicate_rows = duplicate_rows.shape[0]\n",
    "print(\"Number of Duplicate Rows:\", num_duplicate_rows)\n",
    "\n",
    "scenario_variable_2_df = scenario_variable_2_df.drop_duplicates()\n",
    "print(len(scenario_variable_2_df))\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "data_name_df = pd.read_excel(\"../Variable_Reference/Variable_name_IAMC.xlsx\")\n",
    "# Remplacer les tirets du bas par des espaces dans la colonne\n",
    "# data_name_df['WILIAM_variable'] = data_name_df['WILIAM_variable'].str.replace('_', ' ')\n",
    "# Drop rows with NaN values which corresponds to values not conserv for the final upload of data in IAMC format\n",
    "data_name_df.dropna(subset=[\"IAMC_variable\"], inplace=True)\n",
    "data_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_variable_new_df = pd.DataFrame()\n",
    "# Create a dict with Wiliam's name as key, IAMC's name as value\n",
    "IAMC_WILIAM_name_dict = data_name_df.set_index('WILIAM_variable')['IAMC_variable'].to_dict()\n",
    "IAMC_WILIAM_name_dict['economy_dashboard'] = ''\n",
    "IAMC_WILIAM_name_dict['economy_dashboard_1R'] = ''\n",
    "IAMC_WILIAM_name_dict['economy_dashboard_9R'] = ''\n",
    "IAMC_WILIAM_name_dict['economy_dashboard_EU27'] = ''\n",
    "print(IAMC_WILIAM_name_dict)\n",
    "# Replace the variable name used in William to the ones used for IAMC format. \n",
    "scenario_variable_2_df['Old_Variable'] = scenario_variable_2_df['Variable']\n",
    "scenario_variable_2_df['Variable']= scenario_variable_2_df['Variable'].replace(IAMC_WILIAM_name_dict)\n",
    "\n",
    "# Keep only the rows where the value in column 'Variable' belongs to the list of wanted values \n",
    "variable_required_list = data_name_df['IAMC_variable'].to_list()\n",
    "# scenario_variable_df = scenario_variable_df[scenario_variable_df['Variable'].isin(variable_required_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_variable_2_df['Variable'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_used_list = scenario_variable_2_df['Variable'].to_list()\n",
    "variables_required_not_in = list(set(variable_required_list) - set(variables_used_list))\n",
    "print('The missing variable in the export dataset are the following:', variables_required_not_in)\n",
    "print('The number of missing varibles is ', len(variables_required_not_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file containing the energy dictionary\n",
    "with open('../Create_Variable_Dict/energy_dict.txt', 'r') as f:\n",
    "    # Read the contents of the file\n",
    "    energy_dict_str = f.read()\n",
    "\n",
    "# Convert the string representation of the dictionary back to a dictionary object\n",
    "energy_dict = ast.literal_eval(energy_dict_str)\n",
    "\n",
    "\n",
    "# Open the text file containing the rest dictionary\n",
    "with open('../Create_Variable_Dict/rest_dict.txt', 'r') as f:\n",
    "    # Read the contents of the file\n",
    "    rest_dict_str = f.read()\n",
    "\n",
    "# Convert the string representation of the dictionary back to a dictionary object\n",
    "rest_dict = ast.literal_eval(rest_dict_str)\n",
    "\n",
    "\n",
    "# Open the text file containing the sectors dictionary\n",
    "with open('../Create_Variable_Dict/sectors_dict.txt', 'r') as f:\n",
    "    # Read the contents of the file\n",
    "    sectors_str = f.read()\n",
    "\n",
    "# Convert the string representation of the dictionary back to a dictionary object\n",
    "sectors_dict = ast.literal_eval(sectors_str)\n",
    "\n",
    "# Open the text file containing the dictionary\n",
    "with open('../Create_Variable_Dict/country_dict.txt', 'r') as f:\n",
    "    # Read the contents of the file\n",
    "    dict_str = f.read()\n",
    "\n",
    "# Convert the string representation of the dictionary back to a dictionary object\n",
    "country_Wiliam_dict = ast.literal_eval(dict_str)\n",
    "\n",
    "# Open the text file containing the dictionary\n",
    "with open('../Create_Variable_Dict/economy_dashboard_dict.txt', 'r') as f:\n",
    "    # Read the contents of the file\n",
    "    economy_dashboard_str = f.read()\n",
    "\n",
    "# Convert the string representation of the dictionary back to a dictionary object\n",
    "economy_dashboard_dict = ast.literal_eval(economy_dashboard_str)\n",
    "\n",
    "# Open the text file containing the dictionary\n",
    "with open('../Create_Variable_Dict/COICOP_dict.txt', 'r') as f:\n",
    "    # Read the contents of the file\n",
    "    COICOP_dict_str = f.read()\n",
    "\n",
    "# Convert the string representation of the dictionary back to a dictionary object\n",
    "COICOP_dict = ast.literal_eval(COICOP_dict_str)\n",
    "\n",
    "# Open the text file containing the dictionary\n",
    "with open('../Create_Variable_Dict/final_demand_dict.txt', 'r') as f:\n",
    "    # Read the contents of the file\n",
    "    final_demand_dict_str = f.read()\n",
    "\n",
    "# Convert the string representation of the dictionary back to a dictionary object\n",
    "final_demand_dict = ast.literal_eval(final_demand_dict_str)\n",
    "\n",
    "# Open the text file containing the dictionary\n",
    "with open('../Create_Variable_Dict/land_dict.txt', 'r') as f:\n",
    "    # Read the contents of the file\n",
    "    land_dict_str = f.read()\n",
    "\n",
    "# Convert the string representation of the dictionary back to a dictionary object\n",
    "land_dict = ast.literal_eval(land_dict_str)\n",
    "\n",
    "# Open the text file containing the dictionary\n",
    "with open('../Create_Variable_Dict/transport_mode_dict.txt', 'r') as f:\n",
    "    # Read the contents of the file\n",
    "    transport_mode_dict_str = f.read()\n",
    "\n",
    "# Convert the string representation of the dictionary back to a dictionary object\n",
    "transport_mode_dict = ast.literal_eval(transport_mode_dict_str)\n",
    "\n",
    "\n",
    "# Open the text file containing the dictionary\n",
    "with open('../Create_Variable_Dict/transport_power_train_dict.txt', 'r') as f:\n",
    "    # Read the contents of the file\n",
    "    transport_power_train_dict_str = f.read()\n",
    "\n",
    "# Convert the string representation of the dictionary back to a dictionary object\n",
    "transport_power_train_dict = ast.literal_eval(transport_power_train_dict_str)\n",
    "\n",
    "\n",
    "# Open the text file containing the dictionary\n",
    "with open('../Create_Variable_Dict/households_categories_dict.txt', 'r') as f:\n",
    "    # Read the contents of the file\n",
    "    households_categories_dict_str = f.read()\n",
    "\n",
    "# Convert the string representation of the dictionary back to a dictionary object\n",
    "households_categories_dict = ast.literal_eval(households_categories_dict_str)\n",
    "\n",
    "# Replace the region name by the ones adapted for Wiliam. \n",
    "scenario_variable_2_df['Region'] = scenario_variable_2_df['Region'].replace(country_Wiliam_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_string = ['Final Energy|Net[per capita]','Primary Energy[per capita]','Primary Energy|Renewable[Share]','Final Energy|Renewable[Share]','Final Energy|Renewable[Share]', 'Emissions|CO2eq[per capita]','Households|Consumer Price[index]','Final Energy[intensity]','Primary Energy Intensity|GDP[Annual change]']\n",
    "# Fonction pour vérifier la présence d'un mot entier\n",
    "def contains_word(text, words):\n",
    "    for elem in words: \n",
    "        if elem in text: \n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Filtrer le DataFrame en utilisant `apply` avec la fonction lambda\n",
    "filtered_df = scenario_variable_2_df[scenario_variable_2_df['Variable'].apply(lambda text: contains_word(text, list_of_string))]\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict used to check if the subscripts are a country\n",
    "country_dict = {\n",
    "    \"EU27\": 1,\n",
    "    \"UK\": 1,\n",
    "    \"CHINA\": 1,\n",
    "    \"EASOC\": 1,\n",
    "    \"INDIA\": 1,\n",
    "    \"LATAM\": 1,\n",
    "    \"RUSSIA\": 1,\n",
    "    \"USMCA\": 1,\n",
    "    \"LROW\": 1,\n",
    "    \"AUSTRIA\": 1,\n",
    "    \"BELGIUM\": 1,\n",
    "    \"BULGARIA\": 1,\n",
    "    \"CROATIA\": 1,\n",
    "    \"CYPRUS\": 1,\n",
    "    \"CZECH_REPUBLIC\": 1,\n",
    "    \"DENMARK\": 1,\n",
    "    \"ESTONIA\": 1,\n",
    "    \"FINLAND\": 1,\n",
    "    \"FRANCE\": 1,\n",
    "    \"GERMANY\": 1,\n",
    "    \"GREECE\": 1,\n",
    "    \"HUNGARY\": 1,\n",
    "    \"IRELAND\": 1,\n",
    "    \"ITALY\": 1,\n",
    "    \"LATVIA\": 1,\n",
    "    \"LITHUANIA\": 1,\n",
    "    \"LUXEMBOURG\": 1,\n",
    "    \"MALTA\": 1,\n",
    "    \"NETHERLANDS\": 1,\n",
    "    \"POLAND\": 1,\n",
    "    \"PORTUGAL\": 1,\n",
    "    \"ROMANIA\": 1,\n",
    "    \"SLOVAKIA\": 1,\n",
    "    \"SLOVENIA\": 1,\n",
    "    \"SPAIN\": 1,\n",
    "    \"SWEDEN\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Aggregate the subscripts at the end of the variable\n",
    "def aggregate_variable_name(row, counter):\n",
    "    for k in range(counter):\n",
    "        subscript = row[\"Subscript \" + str(k)]\n",
    "\n",
    "        if k == 0:\n",
    "            if country_dict.get(subscript) == 1:\n",
    "                # Give the name of the region for that variable\n",
    "                row[\"Region\"] = subscript\n",
    "\n",
    "                row[\"Subscript 0\"] = np.nan\n",
    "                continue\n",
    "    \n",
    "        if not pd.isnull(subscript):\n",
    "            if energy_dict.get(subscript, None):\n",
    "                subscript = energy_dict[subscript]\n",
    "            elif rest_dict.get(subscript, None):\n",
    "                subscript = rest_dict[subscript]\n",
    "            elif sectors_dict.get(subscript, None):\n",
    "                subscript = sectors_dict[subscript]\n",
    "            elif economy_dashboard_dict.get(subscript, None):\n",
    "                subscript = economy_dashboard_dict[subscript]\n",
    "            elif COICOP_dict.get(subscript, None):\n",
    "                subscript = COICOP_dict[subscript]\n",
    "            elif final_demand_dict.get(subscript, None):\n",
    "                subscript = final_demand_dict[subscript]\n",
    "            elif land_dict.get(subscript, None):\n",
    "                subscript = land_dict[subscript]\n",
    "            elif transport_mode_dict.get(subscript, None):\n",
    "                subscript = transport_mode_dict[subscript]\n",
    "            elif transport_power_train_dict.get(subscript, None):\n",
    "                subscript = transport_power_train_dict[subscript]\n",
    "            elif households_categories_dict.get(subscript, None):\n",
    "                subscript = households_categories_dict[subscript]\n",
    "            \n",
    "            row[\"Variable\"] = row[\"Variable\"] + \"|\" + subscript\n",
    "            \n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "# Apply the previous function on all the lines\n",
    "scenario_variable_2_df = scenario_variable_2_df.apply(\n",
    "    aggregate_variable_name, args=(counter,), axis=1\n",
    ")\n",
    "\n",
    "# Fonction pour vérifier la présence d'un mot entier\n",
    "def contains_word(text, words):\n",
    "    for elem in words: \n",
    "        if elem in text: \n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Filtrer le DataFrame en utilisant `apply` avec la fonction lambda\n",
    "filtered_df = scenario_variable_2_df[scenario_variable_2_df['Variable'].apply(lambda text: contains_word(text, list_of_string))]\n",
    "\n",
    "print(filtered_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour vérifier la présence d'un mot entier\n",
    "def contains_word(text, words):\n",
    "    for elem in words: \n",
    "        if elem in text: \n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Filtrer le DataFrame en utilisant `apply` avec la fonction lambda\n",
    "filtered_df = scenario_variable_2_df[scenario_variable_2_df['Variable'].apply(lambda text: contains_word(text, list_of_string))]\n",
    "\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"scenario_variable_new_df= pd.DataFrame()\n",
    "list_of_string = ['Value|GDP Real']\n",
    "# Fonction pour vérifier la présence d'un mot entier\n",
    "def contains_word(text, words):\n",
    "    for elem in words: \n",
    "        if elem in text: \n",
    "            return True\n",
    "    return False\n",
    "\n",
    "scenario_variable_new_df = scenario_variable_2_df[scenario_variable_2_df['Variable'].apply(lambda text: contains_word(text, list_of_string))]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List with the words in uppercase which will not be capitalized by the next functions\n",
    "upper_word_list = ['CO2', 'CH4', 'N2O', 'PFC', 'SF6', 'HFC134a', 'HFC23', 'HFC32', 'HFC125', 'HFC143a', 'HFC152a', 'HFC227ea', 'HFC245ca', 'HFC4310mee', 'CO2eq[per capita]', 'HFC', 'w/o CCS' ,'w/ CCS', 'PV', 'CSP', 'AFOLU', 'AFOFI' , 'CO2eq', 'EROI', 'PV', 'CSP', 'LMO', 'NMC622', 'NMC811', 'NCA', 'LFP', 'LDV','MDV','HDV','NMT','GDP', 'PPP']\n",
    "vehicule_list = ['gasoline', 'gas' , 'diesel']\n",
    "conjunctions = [\"and\", \"or\", \"nor\", \"but\", \"so\", \"for\", \"yet\", \"of\", \"w/\", \"w/o\"]\n",
    "\n",
    "# Change the format of the string to respect IAMC's format\n",
    "def transform_string(s):\n",
    "    # Split the string into words\n",
    "    if pd.isnull(s): \n",
    "        return s\n",
    "    words = s.split('|')\n",
    "\n",
    "    capitalized_words = []\n",
    "    # Capitalize the first letter of each word\n",
    "    for word in words: \n",
    "        \n",
    "        if any(element in word for element in upper_word_list):\n",
    "            new_word_list = word.split('_')\n",
    "            \n",
    "            word_list=[]\n",
    "            for new_word in new_word_list: \n",
    "                single_element_list =new_word.split(' ')\n",
    "                \n",
    "                single_element_list = [single_element.capitalize() if single_element not in conjunctions and single_element not in upper_word_list else single_element for single_element in single_element_list ]\n",
    "                \n",
    "                word_list += [' '.join(single_element_list)]\n",
    "            \n",
    "            capitalized_words += [' '.join(word_list) + '|']\n",
    "        else:          \n",
    "            capitalized_words += [word + '|']\n",
    "    \n",
    "    # Join the words with spaces\n",
    "    transformed_string = ''.join(capitalized_words)\n",
    "    \n",
    "    result = ''\n",
    "    capitalize_next=False\n",
    "    # Capitalize the letter after each space\n",
    "    for number,char in enumerate(transformed_string[:-1]):\n",
    "        if number == 0 and char == '|': \n",
    "            continue\n",
    "        if char == '-':\n",
    "            capitalize_next = True\n",
    "            result += char\n",
    "        elif capitalize_next:\n",
    "            result += char.upper()\n",
    "            capitalize_next = False\n",
    "        else:\n",
    "            result += char\n",
    "                \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# scenario_variable_new_df = scenario_variable_2_df[scenario_variable_2_df['Variable'].apply(lambda text: contains_word(text, list_of_string))]\n",
    "# Capitalize each variable's name\n",
    "scenario_variable_2_df['Variable'] = scenario_variable_2_df['Variable'].apply(transform_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_variable_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scenario_variable_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour vérifier la présence d'un mot entier\n",
    "def contains_word(text, words):\n",
    "    for elem in words: \n",
    "        if elem in text: \n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Filtrer le DataFrame en utilisant `apply` avec la fonction lambda\n",
    "filtered_2df = scenario_variable_2_df[scenario_variable_2_df['Variable'].apply(lambda text: contains_word(text, list_of_string))]\n",
    "\n",
    "print(filtered_2df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lignes présentes dans df1 mais pas dans df2\n",
    "diff_df1 = filtered_2df[~filtered_2df.isin(filtered_df.to_dict(orient='list')).all(axis=1)]\n",
    "\n",
    "# Lignes présentes dans df2 mais pas dans df1\n",
    "diff_df2 = filtered_df[~filtered_df.isin(filtered_2df.to_dict(orient='list')).all(axis=1)]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Lignes présentes dans df1 mais pas dans df2:\")\n",
    "print(diff_df1['Variable'].unique())\n",
    "\n",
    "print(\"\\nLignes présentes dans df2 mais pas dans df1:\")\n",
    "print(diff_df2['Variable'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make modifications on some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with the name 'Emission'\n",
    "emission_rows = scenario_variable_2_df[scenario_variable_2_df['Variable'].str.contains('Emission')]\n",
    "emission_name_old = emission_rows['Variable'].to_list()\n",
    "# List of Greenhouses Gases used in Wiliam \n",
    "# We differentiate the treatment of HFC and others GHGs because they are handle differently in IAMC Format. \n",
    "GHGs_to_check = ['CH4', 'N2O', 'PFC', 'SF6','CO2']\n",
    "HFC_list = ['HFC134a', 'HFC23', 'HFC32', 'HFC125', 'HFC143a', 'HFC152a', 'HFC227ea', 'HFC245ca', 'HFC4310mee']\n",
    "\n",
    "\n",
    "# Iterate over the rows to create the name and the unit of emissions correctly. \n",
    "# The new list of variables and unit is then updated to the real dataframe.\n",
    "variable_list = []\n",
    "unit_list = []\n",
    "\n",
    "for row_index, row in emission_rows[['Variable','Unit']].iterrows():\n",
    "    specific_word = 'Emissions'\n",
    "    ghg_bool = False\n",
    "    for string in GHGs_to_check:\n",
    "        \n",
    "        if string in row['Variable']:\n",
    "            \n",
    "            index_emission = row['Variable'].find('Emissions') + len(specific_word)\n",
    "            index_gas = row['Variable'].find(string)\n",
    "            row['Variable'] = row['Variable'][:index_emission] + '|' + string + row['Variable'][index_emission:index_gas-1] + row['Variable'][index_gas+len(string):]            \n",
    "            ghg = string\n",
    "            ghg_bool = True\n",
    "        \n",
    "            break\n",
    "    \n",
    "    for string in HFC_list:\n",
    "        if string in row['Variable']:\n",
    "            \n",
    "            index_emission = row['Variable'].find('Emissions') + len(specific_word)\n",
    "            index_gas = row['Variable'].find(string)\n",
    "            row['Variable'] = row['Variable'][:index_emission] + '|HFC|' + string + row['Variable'][index_emission:index_gas-1] + row['Variable'][index_gas+len(string):]\n",
    "            \n",
    "            break\n",
    "    index_year = row['Unit'].find('/yr')\n",
    "    if row['Unit'] == 'Mt/yr' or row['Unit'] == 'Gt/yr':\n",
    "        if ghg_bool: \n",
    "            row['Unit'] = row['Unit'][:index_year] + ' ' + ghg + row['Unit'][index_year:]\n",
    "        else : \n",
    "            row['Unit'] = row['Unit'][:index_year] + ' ' + string + row['Unit'][index_year:]\n",
    "    variable_list.append(row['Variable'])\n",
    "    unit_list.append(row['Unit'])\n",
    "\n",
    "indexes = emission_rows.index\n",
    "\n",
    "# Assign new values to specific rows in the column for the Variable and Unit \n",
    "scenario_variable_2_df.loc[indexes, 'Variable'] = variable_list\n",
    "scenario_variable_2_df.loc[indexes, 'Unit'] = unit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_variable_2_df['Variable'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Primary Energy Naming\n",
    "# Select the rows where the primary energy word \n",
    "energy_rows = scenario_variable_2_df[scenario_variable_2_df['Variable'].str.contains('Per Capita')]\n",
    "\n",
    "\n",
    "energy_name_old = energy_rows['Variable'].to_list()\n",
    "\n",
    "# Function to move the matched string after the specific word\n",
    "def move_crochets(s):\n",
    "    specific_word_1 = '[per capita]'\n",
    "    specific_word_2 = '[intensity]'\n",
    "    specific_word_3 = '[Share]'\n",
    "    specific_word_4 = '[index]'\n",
    "    specific_word_5 = '[per Capita]'\n",
    "    \n",
    "    if specific_word_1 in s:\n",
    "        index_emission = s.find(specific_word_1) \n",
    "        \n",
    "        s = s[:index_emission-1] + s[index_emission+len(specific_word_1):]  + specific_word_1\n",
    "    \n",
    "    if specific_word_2 in s:\n",
    "        index_emission = s.find(specific_word_2) \n",
    "        \n",
    "        s = s[:index_emission-1] + s[index_emission+len(specific_word_2):]  + specific_word_2\n",
    "    \n",
    "    if specific_word_3 in s:\n",
    "        index_emission = s.find(specific_word_3) \n",
    "        \n",
    "        s = s[:index_emission-1] + s[index_emission+len(specific_word_3):]  + '[Share]'\n",
    "\n",
    "    if specific_word_4 in s:\n",
    "        index_emission = s.find(specific_word_4) \n",
    "        \n",
    "        s = s[:index_emission-1] + s[index_emission+len(specific_word_4):]  + '[index]'\n",
    "    \n",
    "    if specific_word_5 in s:\n",
    "        index_emission = s.find(specific_word_5) \n",
    "        \n",
    "        s = s[:index_emission-1] + s[index_emission+len(specific_word_5):]  + specific_word_5\n",
    "\n",
    "    return s\n",
    "\n",
    "# Apply the function to the 'Variable' column\n",
    "\"\"\"energy_rows['Variable'] = energy_rows['Variable'].apply(move_crochets)\n",
    "energy_name_new = energy_rows['Variable'].to_list()\n",
    "\n",
    "energy_per_capita_dict = dict(zip(energy_name_old, energy_name_new))\n",
    "\n",
    "scenario_variable_2_df['Variable'] = scenario_variable_2_df['Variable'].replace(energy_per_capita_dict)\"\"\"\n",
    "scenario_variable_2_df['Variable'] = scenario_variable_2_df['Variable'].apply(move_crochets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Secondary Energy Naming \n",
    "secondary_energy_rows = scenario_variable_2_df[scenario_variable_2_df['Variable'].str.contains('Secondary Energy')]\n",
    "\n",
    "\n",
    "# Change Secondary Energy Naming \n",
    "# Select the rows for Primary Energy Price \n",
    "price_energy_rows = scenario_variable_2_df[scenario_variable_2_df['Variable'].str.contains('Price')]\n",
    "price_energy_rows = price_energy_rows[price_energy_rows['Variable'].str.contains('Primary Energy')]\n",
    "price_energy_rows\n",
    "\n",
    "def remove_characters_between_indices(input_string, start_index, end_index):\n",
    "    \"\"\"\n",
    "    Remove characters between two given indices of a string.\n",
    "\n",
    "    Args:\n",
    "    - input_string (str): The original string.\n",
    "    - start_index (int): The index of the first character to remove (inclusive).\n",
    "    - end_index (int): The index of the last character to remove (inclusive).\n",
    "\n",
    "    Returns:\n",
    "    - str: The modified string with characters removed between the specified indices.\n",
    "    \"\"\"\n",
    "    if start_index >= end_index:\n",
    "        return input_string  # Return the original string if start index is greater than or equal to end index\n",
    "    \n",
    "    # Ensure indices are within the range of the string\n",
    "    start_index = max(start_index, 0)\n",
    "    end_index = min(end_index, len(input_string) - 1)\n",
    "    \n",
    "    # Construct the new string by concatenating substrings before and after the characters to be removed\n",
    "    return input_string[:start_index] + input_string[end_index + 1:]\n",
    "\n",
    "def remove_string_between_pipe(input_string):\n",
    "    \"\"\"\n",
    "    Remove the string between the second and third '|' characters in the input string.\n",
    "\n",
    "    Args:\n",
    "    - input_string (str): The original string.\n",
    "\n",
    "    Returns:\n",
    "    - str: The modified string with the content between '|' characters removed.\n",
    "    \"\"\"\n",
    "    second_occurrence = input_string.find('|', input_string.find('|') + 1)\n",
    "    third_occurrence = input_string.find('|', second_occurrence + 1)-1\n",
    "    \n",
    "    # Remove characters between the '|' characters using the previous function\n",
    "    result = remove_characters_between_indices(input_string, second_occurrence, third_occurrence)\n",
    "\n",
    "    # Remove CCS extension because it is not relevant \n",
    "    result = result.replace('|w/ CCS', '').replace('|w/o CCS', '')\n",
    "    \n",
    "    return result\n",
    "\n",
    "\"\"\"price_energy_rows['Variable'] = price_energy_rows['Variable'].apply(remove_string_between_pipe)\n",
    "indexes = price_energy_rows.index\n",
    "# Assign new values to specific rows in the column for the Variable and Unit \n",
    "scenario_variable_2_df.loc[indexes, 'Variable'] = price_energy_rows['Variable']\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Remove the duplication on the variable column \n",
    "scenario_variable_df = scenario_variable_df.drop_duplicates(subset=[\"Variable\"])\n",
    "print(len(scenario_variable_df))\n",
    "\n",
    "# Step 1: Get the column of old name\n",
    "data_first_column = scenario_variable_df[\"Variable\"].to_list()\n",
    "\n",
    "\n",
    "# Remove the duplication of the Variable column except when the region is 'World'\n",
    "# Assign a temporary index column to keep track of the original order\n",
    "scenario_variable_2_df['temp_index'] = scenario_variable_2_df.index\n",
    "\n",
    "\n",
    "# Drop duplicates based on 'Variable' for non-'World' rows\n",
    "non_world_rows = scenario_variable_2_df.drop_duplicates(subset=['Variable', 'Old_Variable', 'Subscript 1', 'Subscript 2', 'Subscript 3'])\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Get the column of old name\n",
    "data_second_column = non_world_rows[\"Variable\"].to_list()\n",
    "print(len(data_second_column))\n",
    "\n",
    "\n",
    "\n",
    "# Write the new data along with the existing data\n",
    "with open(\"example.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    for k in range(len(data_second_column)):\n",
    "        csvwriter.writerow([data_first_column[k], data_second_column[k]])\n",
    "    for k in range(len(data_second_column), len(data_first_column)): \n",
    "        csvwriter.writerow([data_first_column[k]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IAMC_format",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
